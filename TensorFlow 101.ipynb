{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tensor ( multidimensional data) flowing through a Graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Opensource Machine Learning Library\n",
    "* Mainly for Deep Learning\n",
    "* For both Research and Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ድግስFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Two stages\n",
    "\n",
    "    * Coocking using the Recipe\n",
    "    \n",
    "    * Serving the Guests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about TensorFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Same as ድግስFlow, it's just...\n",
    "    * Graph\n",
    "    * Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A collection of Nodes or Coputations.\n",
    "* Defined in high-level Languages ( e.g. Python)\n",
    "* Executed on available low level devices (e.g CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Session?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Operation Excution \n",
    "* Tensor evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's CODE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax ( Multinomial Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloading or just importing the MNIST dataset from tensorflow examples\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Extracting the data and loading it into a variable\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantity of the images in the dataset\n",
    "mnist.train.num_examples, mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomly selecting an image to display and see what is  looks like\n",
    "random_image = mnist.train.images[10000].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f16fd953150>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwRF+IGgCD8QFOEHgiL8QFCEHwjq/2B7ZevcAyhQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16fda760d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying an image on the axes\n",
    "plt.imshow(random_image, cmap=\"gist_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking wether the data is notmalized or not\n",
    "random_image.min(), random_image.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build the graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Logistic Regression interms of mathematical equation is:\n",
    "\n",
    "     y = Wx + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* x = the image data to be feed in the session\n",
    "* W = the wight \n",
    "* b = the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder for the training dataset\n",
    "# Vectorized_image_Data.shape = 28*28 --. 784\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(784)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declaring and initializing Variables into zero!\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the Logit or Score of the computation\n",
    "y = tf.matmul(x,w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Let's Create the Session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 90.0900006294\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for steps in range(1000):\n",
    "        \n",
    "        x_batch, y_batch = mnist.train.next_batch(100)\n",
    "        \n",
    "        sess.run(train, feed_dict={x:x_batch, y_true:y_batch})\n",
    "        \n",
    "    # Evaluate the model\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_true, 1))\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy = \"+ str(sess.run(accuracy, feed_dict = {x:mnist.test.images, y_true:mnist.test.labels})*100))\n",
    "    \n",
    "    #print(sess.run(accuracy, feed_dict = {x:mnist.test.images, y_true:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
